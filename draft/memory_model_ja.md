title: メモリモデルとはなにか
timestamp: 2022-01-20 12:00:00
lang: ja
---

## 概要

マルチスレッドプログラミングにおいては、プログラム1行1行の実行順序がプログラマの直感に反することがある。以下の例を見てみよう。スレッド1と2はそれぞれ別のスレッド (コア) で同時に実行される。またここでは、すべての変数は初期値をゼロとする。

```
# スレッド1
x = 1
y = 1

# スレッド2
r1 = y
r2 = x
```

この時、このプログラムの各行の実行順序は次のように考えられるだろう。

1. スレッド1 ->  スレッド2と実行されたケース

```
x = 1
y = 1
		r1 = y // r1は1
		r2 = x // r2は1
```

2. スレッド2 ->  スレッド1と実行されたケース。
```
		r1 = y // r1は0
		r2 = x // r2は0
x = 1
y = 1
```

3. 各行がインターリーブされたケース。インターリーブのパターンは4通りある。

```
# パターン1
x = 1
		r1 = y // r1は0
y = 1
		r2 = x // r2は1
```

```
# パターン2
x = 1
		r1 = y // r1は0
		r2 = x // r2は1
y = 1
```

```
# パターン3
		r1 = y // r1は0
x = 1
		r2 = x // r2は1
y = 1
```

```
# パターン4
		r1 = y // r1は0
x = 1
y = 1
		r2 = x // r2は1
```

r1とr2の組み合わせは、1のケースで `{1, 1}` 、2のケースで `{0, 0}` 、3のケースは複数のパターンがあるがいずれも `{1, 0}` となることがわかる。

では、r1とr2が `{0, 1}` となることはあり得ないのだろうか？実は場合によっては、 `{0, 1}` になることがある。

上のいずれもケースも、スレッド1・2は、それぞれが自スレッド内での命令実行順を変えない (プログラムで指定された通りの順序で命令が実行される) ことを前提としていた。実はこの前提は必ずしも正しくない。なぜならこの前提は、プロセッサとコンパイラによる最適化を考慮していないためである。プロセッサとコンパイラは、最適化のために命令の順序を変えることがある。しかし、これではプログラマが困ってしまうので、「メモリ上に保存されたデータの可視性と一貫性について定められたルール」が設けられる。このルールのことを「メモリ一貫性モデル」あるいは単に「メモリモデル」などと呼ぶ。

すなわちメモリモデルには、プロセッサを話題とする「ハードウェア・メモリモデル」と、コンパイラを話題とする「ソフトウェア・メモリモデル」の2種類が存在する。筆者は個人的に、メモリモデルという言葉がこれらをあまり区別せず使われていることが、メモリモデルのわかりにくさの理由の一つではないかと考えている。

この記事では、メモリモデルを理解するために必要な一貫性に関する知識をまず解説し、その後ハードウェア・ソフトウェアに分けてメモリモデルについて書いていく。また最後に、Goにおけるメモリモデルがどのように定義されているのかを概観していく。

## なぜメモリモデルを学ぶのか

JavaやC++、Goといった高級言語でマルチスレッドプログラミングを書く時、メモリモデルの知識は必ずしも必要ない。Goではチャネルやsync/atomic、あるいはsync.Mutexなどの仕組みが既に用意されているため、これらを適切に使えればプログラムはプログラマが普通に考える通り動作する。したがって、プログラマに必要な知識はメモリモデルのような低レイヤな話題ではなく、ライブラリの適切な使用方法や並列処理設計といった高レイヤな部分である。

[The Go Memory Model](https://go.dev/ref/mem)の冒頭には、次のようにある。

> If you must read the rest of this document to understand the behavior of your program, you are being too clever.

> Don't be clever.

メモリモデルを理解している必要があるのは、OSカーネルや並行・並列処理ライブラリ、コンパイラなどの開発者である。マルチスレッドプログラミングを書く開発者は必ずしもメモリモデルを学ぶ必要はない。筆者がメモリモデルについて勉強してこのブログまで書いている理由は、単に興味があっておもしろそうだったからでしかないので、そういう前提でこれより下は読んでいただきたい。

## 逐次一貫性

まずはハードウェア・ソフトウェア関係なく、メモリモデルを理解するために必須な知識である「逐次一貫性」について。
逐次一貫性 ([Sequential Consistency](https://jepsen.io/consistency/models/sequential)) とは並行システムにおける一貫性モデルのひとつである。これ自体は単なる一貫性モデルのひとつなので、メモリモデルやマルチスレッドプログラミングとは独立して理解可能である。これから「プロセッサ」や「スレッド」という言葉を使って逐次一貫性を説明するが、これはわかりやすさのためであって、一貫性モデル自体はプロセッサやOSのスレッドとは独立した概念であることに注意して欲しい。

### 逐次一貫性の定義の

逐次一貫性は、1979年のLeslie Lamportの論文「[How to Make a Multiprocessor Computer That Correctly Executes Multiprocess Programs](https://www.microsoft.com/en-us/research/publication/make-multiprocessor-computer-correctly-executes-multiprocess-programs/)」でその定義が与えられている。

> … the result of any execution is the same as if the operations of all the processors were executed in some sequential order, and the operations of each individual processor appear in this sequence in the order specified by its program.

[Wikipedia](https://ja.wikipedia.org/wiki/%E9%80%90%E6%AC%A1%E4%B8%80%E8%B2%AB%E6%80%A7)では以下のように訳されている。

> 「どのような実行結果も、すべてのプロセッサがある順序で逐次的に実行した結果と等しく、かつ、個々のプロセッサの処理順序がプログラムで指定された通りであること」

### 逐次一貫性は何を許し、何を許さないのか

個々のプロセッサは完全に並列で動作するので、プロセッサAのある操作と、プロセッサBのある操作がどのような順序で発生するかは未定義である。しかし、プロセッサA・Bともに、個々のプロセッサ内での処理順序はプログラム上で示される指定順序と同じになる。

こういった一貫性モデルには[多くの種類がある](https://en.wikipedia.org/wiki/Consistency_model)が、逐次一貫性は比較的強いモデルである (Strong consistencyと呼ばれる一貫性モデルのひとつである) 。例えば、weak consistencyに分類される、最近はマイクロサービスなどの文脈でよく言及される[結果整合性](https://en.wikipedia.org/wiki/Eventual_consistency)という一貫性モデルがある。結果整合性が保証するのは「ある操作はいずれ見えるようになる」(いつかは不明)ということだけなので、一度見えた値が巻き戻ったり、あるプロセッサが施した操作がそれとは異なる順番で見えるようになったりすることがあり得る。言い方を変えれば、あり得ないことを特に保証していない一貫性モデルである。

逐次一貫性は、各プロセッサはプログラムを書かれた順番に実行することを保証するが、一方で各プロセッサが実行する命令の順序については保証しておらず、入れ替わる可能性がある。これはすなわち、各プロセッサが実行する命令は任意の順序にインターリーブされうることを意味する。すなわち、以下の例を考えると、

```
# スレッド1
op_1()
op_2()

# スレッド2
op_3()
op_4()
```

__op_1はop_2よりも前に発生すること__ と __op_3はop_4の前に発生すること__ を逐次一貫性は保証する。しかし、op_3がop_1より前か、op_1とop_2の間にインターリーブされるか、あるいはop_2の後かは保証されない。

…と色々と書いてきたが、これらはプログラマの直感に違反するものではないだろう。書いた通りの順序で実行されるが、マルチスレッドとなるとスレッド間では命令の順序は (当然のごとく) ひとつに定まらないよ、というだけのことである。これらはプログラマにとって自然であり、かつ理想的であると考えられている (本当にこれが理想的か?というのはまた別の話である) 。

さて、メモリモデルについてのポストにも関わらず逐次一貫性について説明しているのには理由がある。逐次一貫性は、前述したコンパイラとプロセッサによる最適化を目的とした命令の順序の入れ替えに大きく関連している。というのは、逐次一貫性を諦めることで、プロセッサ・コンパイラはプログラムの実行を高速化できるのである。
次章からは、プロセッサ及びコンパイラがそれぞれどのように命令の順序を変更するのか、それに対してどうメモリモデルが関係するのかを見ていく。

## ハードウェア・メモリモデル

まずはハードウェア、すなわちプロセッサにおけるメモリモデルから。
マルチプロセッサのシステムでは、あるコアによるメモリへのロードやストアが、ほかのコアから可視になる順序が、プログラムの順序と異なることが発生する。なお、この章はハードウェアについて話しているので、ここでいうプログラムとは高級言語ではなくアセンブリ (または機械語) である。

### プロセッサの最適化

[Latency Numbers Every Programmer Should Know](https://gist.github.com/jboner/2841832)によれば、プロセッサのメインメモリ参照のレイテンシは、L1キャッシュ参照の200倍の時間がかかるらしい。プロセッサから見るとメモリアクセスは極めて時間がかかるので、メモリへのアクセスをなるべく不要にすることはプロセッサの設計において重要な観点である。プロセッサの設計は当然各CPUベンダで異なっており、それが結果的に各プロセッサで異なるメモリモデルとなった。

前述したように、プロセッサは最適化を目的として命令の順序を入れ替えることがある。しかし、特にルールがなく順序を自由に入れ替えてしまうとプログラムは正しく実行されなくなってしまうので、各CPUベンダは自社のプロセッサがどのようにメモリアクセスの順序を変更できるのかを定めている。この「メモリアクセスの順序変更に関するルール」を、メモリアクセスのセマンティクスと呼ぶ。そして、複数のメモリアクセスのセマンティクスをまとめた「あるプロセッサにおけるメモリアクセスの順序に関するモデル」のことをハードウェアにおけるメモリモデルと呼ぶ。

まず、メモリアクセスのセマンティクスとはどのようなものがあるかというと、以下のようなものがある:

* ロードの後にロードを並び替えることができる
* ストアの後にロードを並び替えることができる
* ストアの後にストアを並び替えることができる
* ロードの後にストアを並び替えることができる
* アトミックとロードを並び替えることができる
* アトミックとストアを並べ替えることができる
* 依存関係のあるロード同士を並べ替えることができる
* インコヒーレントな命令キャッシュパイプライン

例えば、ロードの後にロードを並べ替えるとは以下のようなことである。

```asm
r1 = x // op1
r2 = y // op2
```

上記のコードはメモリのx番地、y番地からr1、r2に対してロードを行っているが、これらの順序が入れ替わって op2 -> op1の順序で実行された場合、ロードの後にロードが並び替えられたことになる。

こういった順序変更を明示的に禁止するには、__メモリバリア__ (あるいは__メモリフェンス__) と呼ばれる命令を使う。例えば、上記のコードを以下のように変更することで、op1とop2の順序変更は発生しなくなる。

```asm
r1 = x // op1
Memory_barrier
r2 = y // op2
```

メモリバリア命令は文字通りバリアとして、op1とop2の順序変更が行われないことを保証する。

あるアーキテクチャがどのセマンティクスを守っていて、どのセマンティクスは保証していないかは次の通り。

// 図

チェックが多く入っているほど順序変更が起こりやすいアーキテクチャと言える。そして、順序変更が起こりやすいメモリモデルは「弱いメモリモデル」と呼ばれ、順序変更が起きにくいメモリモデルは「強いメモリモデル」と呼ばれる。しかし、この図の通り、実際は強いか弱いかの二択ではなく、アーキテクチャによってかなり異なっている。

例えば、Alphaプロセッサでは依存関係のあるロードの並べ替えが許されている。これは、Alphaプロセッサ (Alpha21264ベースのプロセッサ) では以下のようなことが発生し得る: 

```
# 初期状態: p = &x, x = 1, y = 0

# スレッド1
y = 1
Memory_barrier
p = &y

# スレッド2
i = &p
```

Alpha21264ベースのプロセッサを備えたコンピュータ[^1]では、このプログラムを実行した結果iが0になり得る。

スレッド1ではメモリバリア命令があるので、 `y = 1` と `p=&y` の順序が逆転することはない。スレッド2の `i = &p` がどうインターリーブされうるかと言うと (メモリバリア命令は省略する):

```
		i = &p // iは1
y=1
p=&y
```

```
y=1
		i = &p // iは1
p=&y
```

```
y=1
p=&y
		i = &p // iは1
```

となるので、iが0になることはなさそうである。しかし、Alpha212264プロセッサではこれがあり得る[^2]。

図の通り、こういった依存関係のあるロードの順序変更はほかのアーキテクチャでは発生しない。例えばARMv7プロセッサではこういった順序変更が発生しないため、ARMv7はAlphaよりも強いメモリモデルを備えていると言われる。

### x86アーキテクチャのメモリモデル - TSO

例として、x86アーキテクチャのメモリモデルについて考える。
x86アーキテクチャのコアとメモリの関係は次のように図示される。

// 図

x86アーキテクチャは、メモリへの書き込みは直接メモリに到達せず、Store bufferと呼ばれるFIFOキューにいったん入る。読み取りの際はまずStore bufferに読みたいメモリアドレスへの書き込みがあるかを検索し、あればその書き込みで書き込もうとしている値を読み取る。また、x86アーキテクチャのポイントの重要なポイントは、あるStore bufferから実際にメモリに書き込まれた以降、他のコアからそのメモリへの読み取りはStore bufferではなく確実にメモリから読まれるようになる。つまり、メモリへの書き込みが発生すると他のコアが持つキャッシュは破棄されるので、Alphaプロセッサのように古い値を読むことはなく、コヒーレンシが保たれるようになっている。
このモデルはTSO ( _Total store order_ ) と呼ばれる。

TSOは、メモリの読み取りは即時で最新の値を読むため、以下のコードを実行した時にr1=1 && r2=0になることは絶対にない。

```
# スレッド (コア) 1
x = 1
y = 1

# スレッド (コア) 2
r1 = y
r2 = x
```

TSOのStore bufferはFIFOであるし、図の通りTSOではストアとストアは順序変更されないので、スレッド1によるストアはx=1 -> y=1が保証される。
また、ロードとロードも順序変更はされないので、スレッド2のロードの順序もプログラムで指定された順序と同じになる。
従って、上記のプログラムを実行する時、TSOモデルは __逐次一貫性の保証されたハードウェアと同様のふるまいをする__ と言える。

しかし、これだけではTSOモデルは逐次一貫性を保証しているとは言えない。以下のようなプログラムを考える。

```
# スレッド (コア) 1
x = 1
r1 = y

# スレッド (コア) 2
y = 1
r2 = x
```

逐次一貫性を保証するハードウェアでは、{r1, r2} は確実に {1, 0} {0, 1} {1, 1} のいずれかになる。
しかし、TSOでは {0, 0} がありえる。図の通り、TSOではストアがロードの後に順序変更されることがありえるため、スレッド1のx=1とr1=yは順序が逆転しうる (スレッド2も同様) ためである。
内部的には、スレッド1とスレッド2がStore bufferにそれぞれx=1 y=1をストアして、その後Store bufferからメモリに書かれる前にyとxの値をメモリから読み取った場合、上記のように {0, 0} になることになる。

つまり、TSOは逐次一貫性を保証していないと言える。

このプログラムを修正するには、以下のようにバリアを入れて順序変更をプログラマが明示的に禁止すれば良い。

```
# スレッド (コア) 1
x = 1
Memory_barrier
r1 = y

# スレッド (コア) 2
y = 1
Memory_barrier
r2 = x
```

### ハードウェア・メモリモデルとはなにか

ハードウェア・メモリモデルとは、あるプロセッサがメモリにアクセスする順序に関する保証のことである。上で紹介したTSO以外にも、WMO、RMO、PSOなど種類が多くあるものの、ほとんどは逐次一貫性を満たしていない。プロセッサは命令実行数を上げるために順序変更をするよ、どのような順序変更が起きるかはメモリモデルとして定義しているので、コンパイラ開発者はそれを読んで、必要ならバリアを明示的に入れればいいよ、というのがプロセッサの気持ちなのだと思われる。

さて、筆者のようなGoプログラマは直接アセンブリを書いたりメモリバリアを意識したプログラムを書くことはほぼなく、並行処理はプログラミング言語が提供する仕組みを利用している。しかし、筆者が書いたGoのコードは最終的に機械語になることを考えると、その機械語の中には当然メモリバリア命令は使われているはずである。なぜ私達のような普通のプログラマはそれを意識しなくてもよいのだろうか?それはプログラミング言語がプログラマに提供する「ソフトウェア・メモリモデル」と大きく関係している。次の章からは、メモリモデルをソフトウェアの観点から見ていく。

## ソフトウェア・メモリモデル

## メモリモデル in Go

[^1]: Linus Torvaldsが、Alphaの中でもごく一部のハードウェアでしか起きないよ、とどこかで言っていたらしい https://stackoverflow.com/questions/35115634/dependent-loads-reordering-in-cpu#comment57952162_35115634
[^2]: [Reordering on an Alpha processor](https://www.cs.umd.edu/~pugh/java/memoryModel/AlphaReordering.html)によれば、スレッド2を実行するコアのキャッシュにy=0が載っているときに、スレッド1がy=1を実行すると、スレッド2のキャッシュのインバリデーションが送られるが、スレッド1はインバリデーション完了を待たずに処理を継続するため (パフォーマンスのために)、iは0になり得るらしい
